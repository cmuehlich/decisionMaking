# ------------ Scenario Settings ------------
# Available scenarios:
# ["MountainCar-v0"]
env: "MountainCar-v0"
env_episodes: 1000
episode_duration: 200
# ------------ Solver Settings ------------
# Available Solver:
#  [value_iteration, policy_iteration, mcm, tdl_sarsa, tdl_expected_sarsa, tdl_q_learning, tdl_double_q_learning,
#  tdl_n_step_sarsa, dyna_q, mcts, tdl_grad_sarsa, tdl_true_online_sarsa, mc_reinforce, actor_critic]
solver: "actor_critic"
# ------------  General Parameters ------------
discount_factor: 0.9
epsilon_greedy: 0.1
learning_rate: 0.0000125
baseline_learning_rate: 0.000125
state_dim: 100 # for discretized state space
plot_results: True
# ------------  Dynamic Programming ------------
convergenc_criteria: 1.1
# ------------  Monte Carlo Learning ------------
# ["first_visit", "all_visit"]
mc_variant: "all_visit"
# ------------ Temporal Difference Learning ------------
td_lambda: 0.84
eligibility_trace: True
# --- SARSA
n_step: 5
# --- Q-Learning
# [sum, average, max]
dq_learning_merging_operator: "sum"
# ------------ Monte Carlo Tree Search ------------
n_simulations: 25
ucb_alpha: 0.5
mcts_iterations: 10







