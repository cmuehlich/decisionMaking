# ------------ Scenario Settings ------------
env: "MountainCar-v0"
env_episodes: 1000
episode_duration: 200
# ------------ Solver Settings ------------
# Available Solver:
#  [value_iteration, policy_iteration, mcm_first_visit, mcm_all_visit, tdl_sarsa, tdl_expected_sarsa
#  tdl_q_learning, tdl_double_q_learning, tdl_n_step_sarsa, dyna_q, mcts, tdl_grad_sarsa, tdl_true_online_sarsa,
#  mc_reinforce, actor_critic]
solver: "actor_critic"
# ------------  General Parameters ------------
convergenc_criteria: 1.1
discount_factor: 0.9
epsilon_greedy: 0.1
learning_rate: 0.0125
baseline_learning_rate: 0.00125
state_dim: 100 # for discretized state space
plot_results: True
# ------------  Monte Carlo Learning ------------
# ["first_visit", "all_visit"]
mc_variant: "first_visit"
# ------------ Temporal Difference Learning ------------
td_lambda: 0.84
eligibility_trace: True
# --- SARSA
n_step: 5
# --- Q-Learning
# [sum, average, max]
dq_learning_merging_operator: "sum"
# ------------ Monte Carlo Tree Search ------------
n_simulations: 25
ucb_alpha: 0.5
mcts_iterations: 10







